# 011.features.01: Batch Action Execution

**Status:** Pending
**Priority:** High

## Objective

Allow the LLM to plan and return multiple actions per cycle, executed in rapid sequence with lightweight bail-out checks between each. Reduces LLM round-trips for predictable multi-step interactions (e.g., click search field → type query → press Enter).

## Context

Each iteration of the main loop in `runGoal()` performs a full SENSE-PLAN-ACT cycle. The LLM call dominates at 2-10 seconds per action. Many real-world interactions are naturally multi-step sequences that don't require intermediate re-sensing. Action batching lets the LLM plan these sequences in one call, then execute them rapidly without redundant LLM round-trips.

**Examples of good batches:**
- Click a search field, type a query, press Enter (3 actions)
- Click a dropdown, then click a visible option (2 actions)
- Scroll down, then click an element visible in the element list (2 actions)

**Examples of bad batches (should stay single-action):**
- Click a link that navigates to a new page
- Submit a form when the result page is unknown
- Any action where the next step depends on what loads

## Technical Details

### Architecture

The change touches three layers:

1. **Types layer** (`src/lib/llm.ts`): New `BatchThinkingResult` type with `actions: Action[]` instead of `action: Action`. Parser accepts both formats for backward compatibility.
2. **Prompt layer** (`src/lib/llm.ts`): System prompt updated to teach the LLM about action sequences — when to batch, how many actions, and guidance.
3. **Execution layer** (`src/lib/session.ts`): New `executeBatch()` function that iterates through actions with bail-out checks. Main loop restructured to consume `BatchThinkingResult`.

### Files to Modify

| File | Changes |
|------|---------|
| `src/lib/llm.ts` | Add `BatchThinkingResult` type, update parsers for `actions[]`, update prompts with batching schema/guidance, add `formatBatchFeedback()` and `formatBatchActions()` |
| `src/lib/session.ts` | Add `executeBatch()` function with bail-out logic, restructure main loop in `runGoal()` |
| `src/index.ts` | Export new types and functions |

### Files NOT Changed

| File | Reason |
|------|--------|
| `src/lib/action-executor.ts` | `executeAction()` handles individual actions; batch loop calls it repeatedly |
| `src/cli.ts` | `onAction` callback fires per action in batch — spinner updates work naturally |
| `src/lib/page-analyzer.ts` | Sensing unchanged; only execution is batched |

### Implementation Steps

#### Step 1: Types and Parser (`src/lib/llm.ts`)

New types:

```typescript
export interface BatchThinkingResult {
  thought: string;       // Persona monologue (covers the whole plan)
  actions: Action[];     // Ordered sequence, 1-6 actions
  confidence: number;
}

export interface VisionBatchThinkingResult {
  thought: string;
  actions: VisionAction[];
  confidence: number;
}
```

Normalizer for backward compatibility:

```typescript
export function normalizeToBatch(
  result: ThinkingResult | BatchThinkingResult
): BatchThinkingResult {
  if ('action' in result && !('actions' in result)) {
    return { thought: result.thought, actions: [result.action], confidence: result.confidence };
  }
  return result as BatchThinkingResult;
}
```

Parser (`parseResponse()`) accepts either `action` (single object) or `actions` (array). Cap batch at 8 actions defensively. Same treatment for `parseVisionResponse()`.

Return types of `getNextAction()` and `getNextActionFromScreenshot()` change to `Promise<BatchThinkingResult>` and `Promise<VisionBatchThinkingResult>`.

#### Step 2: Prompt Updates (`src/lib/llm.ts`)

Update response schema in `buildSystemPrompt()` and `buildVisionSystemPrompt()`:

```
Your response MUST be valid JSON with this exact structure:
{
  "thought": "Your internal monologue as this persona",
  "actions": [
    {
      "type": "click|type|press|scroll|hover|drag|wait|done|failed",
      "elementId": <number>,
      "selector": "<selector>",
      "text": "<text to type>",
      "key": "<key to press>",
      "direction": "up|down",
      "amount": <pixels>,
      "duration": <ms>,
      "reason": "<why done or failed>"
    }
  ],
  "confidence": <0.0 to 1.0>
}

ACTION BATCHING:
You may include MULTIPLE actions when confident they can execute in rapid
sequence WITHOUT needing to re-read the page. Keep batches SHORT (2-4 actions).
Use a single action when uncertain what happens next.

"done" and "failed" must ALWAYS be the LAST action in the array.
```

Add `formatBatchFeedback()` to summarize batch results for the next LLM call:

```typescript
export function formatBatchFeedback(
  results: Array<{ actionDesc: string; success: boolean; error?: string }>
): string
```

#### Step 3: Batch Execution (`src/lib/session.ts`)

New `executeBatch()` function with bail-out checks between each action:

```typescript
interface BatchExecutionResult {
  results: BatchActionResult[];
  completedCount: number;
  terminalAction?: Action;  // Set if done/failed reached
  urlChanged: boolean;
}
```

**Bail-out triggers** (checked between each action):

1. **Action execution failure** — `executeAction()` returns `{ success: false }`. Bail immediately.
2. **URL change** — Quick `window.location.href` check (~5ms). If navigation occurred, remaining actions target the wrong page. Bail.
3. **Target element missing** — Quick `document.querySelector(selector)` check (~5ms). If the next action's target disappeared, bail.
4. **Terminal action** — If next action is `done` or `failed`, stop executing and return it for the main loop to handle.

On bail-out, execution stops and the main loop returns to full SENSE phase — re-analyze page, feed new state to LLM, get fresh plan.

**Inter-action settle**: Between each action, call `waitForDOMSettle(browser)` from 013.core.01 (Adaptive DOM Settle Detection). This is a MutationObserver-based detector that resolves when the DOM stops changing — see that task for full implementation details, behavior across site types, and known risks.

For batch execution, the key behavior is:
- Static page actions: settles in ~20ms (fast batch)
- React/framework actions: settles in ~100-150ms (matches render cycle)
- Actions that trigger API calls: settles in ~500ms-2s (waits for content)
- Chatty DOM (ads, analytics): hits 2s hard cap (same as current `waitForLoaded()`)

If an action within a batch causes navigation (detected by URL change bail-out), `waitForDOMSettle()` is skipped — the bail-out fires before settle is needed.

**Main loop restructure** in `runGoal()`:
1. Show speech bubble (once, with the thought covering the full plan)
2. Execute batch via `executeBatch()`
3. Handle terminal action if present
4. Build feedback from all results via `formatBatchFeedback()`
5. Increment `actionCount` by completed count
6. Continue to next SENSE cycle

#### Step 4: Export Updates (`src/index.ts`)

Add exports for `BatchThinkingResult`, `VisionBatchThinkingResult`, `formatBatchActions`, `formatBatchFeedback`, `normalizeToBatch`.

### Known Risks and Mitigations

#### Risk 1: LLM won't batch well (HIGH)

The LLM must judge which actions are safe to batch. It will likely:
- **Over-batch**: Include a click that causes navigation, invalidating subsequent actions
- **Under-batch**: Always return 1 action, negating the feature entirely
- **Be inconsistent**: Sometimes batch dangerous sequences, sometimes refuse safe ones

**Mitigations:**
- Prompt with explicit **positive examples** (click field + type + press Enter) AND **negative examples** (click link that navigates, submit form with unknown result)
- Track batching metrics: how often does the LLM batch? How often do batches bail? If bail rate > 50%, the prompt needs tuning or the feature is hurting more than helping
- Consider a **warmup period**: first N actions per goal are always single-action, then batching is allowed once the LLM has context about the site's behavior

#### Risk 2: elementId staleness within a batch (MEDIUM)

The LLM references element IDs from the SENSE snapshot. If action 1 changes the DOM (e.g., opens a dropdown), element IDs become stale. The pre-flight `querySelector(selector)` check may pass (selector still exists) but the element may now represent something different.

**Mitigations:**
- The bail-out check should verify not just selector existence but also element **visibility** — a quick `el.offsetParent !== null` or `el.getBoundingClientRect().height > 0` check
- Accept this as a known limitation. Batches that modify the DOM (open dropdown → click option) are inherently risky. The prompt should teach: "only batch actions where no action creates or removes elements"

#### Risk 3: Chatty DOMs defeat MutationObserver settle detection (MEDIUM)

`waitForDOMSettle()` resolves when no mutations arrive for 100ms. But sites with ads, analytics pixels, live chat widgets, animated backgrounds, or WebSocket-driven updates mutate constantly. The observer never goes quiet, always hitting the 2s hard cap.

**Impact:** On chatty sites, every inter-action wait becomes 2s — worse than a fixed 150ms delay and equal to the current full `waitForLoaded()` timeout. The batch speed advantage is lost.

**Mitigations:**
- Accept the 2s hard cap as safe default. Worst case matches current single-action behavior.
- **Future optimization**: Scope the observer to the subtree near the action's target element instead of `document.body`. Mutations in an ad sidebar are irrelevant when executing actions on a search form.
- **Future optimization**: Filter mutations by relevance — ignore attribute changes on elements with `data-testid` containing "ad", "analytics", "tracking", or similar patterns.

#### Risk 4: Speech bubble pacing breaks for viewers (LOW)

Currently: show thought → typing animation → thinking pause → ONE action. With batches: show thought → typing animation → thinking pause → 3 actions rapid-fire. The viewer loses the per-action narrative.

**Mitigation:**
- Accept this tradeoff. The thought already covers the full plan ("I'll search for earrings by clicking the search field, typing my query, and pressing Enter"). The rapid execution is actually more natural than the current artificial pauses.
- If it's a problem in practice, a future enhancement could show mini-annotations per action within the batch.

#### Risk 5: Session persistence format conflict (LOW)

LLM sessions using `--resume` have the old `action` schema in their history. The LLM may continue producing single actions despite the updated prompt.

**Mitigation:**
- The normalizer handles this gracefully — single `action` is wrapped in an array. This is not a functional problem, just a reduced batching rate for the first session after deployment.
- New sessions use the new schema from the start.

### Edge Cases

| Case | Handling |
|------|----------|
| LLM returns single `action` (old format) | Parser wraps in array. Batch of 1 = current behavior |
| LLM returns both `action` AND `actions` | Prefer `actions` array. Ignore `action` field. |
| `actions` is not an array | Wrap in array (defensive). Log a warning. |
| Terminal action mid-batch (`[click, done]`) | Execute click, return `done` as `terminalAction` |
| Document read in batch | Works, but read content not available to LLM until next cycle. **Hard-fail**: if a `document.read` is followed by any non-terminal action in the batch, strip the trailing actions and treat as read-only batch. Don't rely on prompt guidance for this. |
| Vision mode + batch | Resolution loop maps `elementId` to `selector` for all actions at batch start. If any action targets an elementId that doesn't resolve, truncate batch there. Accept that post-action-1 element staleness is a fundamental limitation of vision batching. |
| Observer timing | Runs once per SENSE-PLAN cycle (not per action). Observer will miss intermediate states during batch execution. For observation-heavy goals (document/note-taking), this is a real gap — consider forcing single-action mode when observer is enabled. |
| Max batch size | Parser caps at 8. Prompt guides toward 2-4 |
| Action count / timeout | `actionCount` increments by completed count. 100-action limit and timeout still checked per main loop iteration |

### Performance Impact

- **Savings (best case)**: Each batch of N actions saves (N-1) LLM calls (2-10s each) and (N-1) page analysis cycles (~50-200ms each). A 3-action search flow saves 4-20 seconds.
- **Overhead per action**: Pre-flight check ~5-10ms, URL check ~5ms, DOM settle ~20ms-2s (adaptive). Total for 3-action batch on a responsive site: ~100-200ms overhead vs. 4-20s saved. On a chatty/slow site: ~4-6s overhead (still less than 3 full LLM round-trips).
- **Savings (worst case)**: LLM never batches → zero overhead, zero savings. Feature is invisible. This is acceptable — the normalizer makes single-action responses behave identically to current code.
- **Anti-savings (failure case)**: LLM batches aggressively, bail rate is high. Each bail adds overhead (partial execution + re-sensing) compared to single-action. **Track bail rate and disable batching if it exceeds 50% over a session.**
- **Observer**: Runs less frequently, reducing total LLM cost. But misses intermediate states.

## Testing

- Run against existing personas to verify backward compatibility (LLM may still return single actions)
- Verify batch execution with search scenarios (click + type + press Enter)
- Verify bail-out when URL changes mid-batch
- Verify terminal action handling mid-batch
- Verify vision mode works with batches
- **Parser robustness**: Test with `action` only, `actions` only, both present, `actions` as non-array, empty `actions` array
- **Document read truncation**: Verify that `[document.read, click]` is truncated to `[document.read]`
- **Bail rate tracking**: Log per-session batch stats (total batches, total actions, bail count, bail reasons) to debug output. This is critical for tuning.
- **DOM settle integration**: Verify batch execution uses `waitForDOMSettle()` between actions (not fixed delays). Settle timing tests are in 013.core.01.

## Dependencies

- **013.core.01 (Adaptive DOM Settle Detection)**: `waitForDOMSettle()` is used as the inter-action timing mechanism between batched actions. Must land first — batch execution relies on adaptive settle rather than a fixed delay.

## Foundation For

- 012.features.01: Domain Knowledge & Learned Assertions (builds on batch execution to add state observation and assertion checking). **Note**: Task 18's state observer and `waitForDOMSettle()` (013.core.01) can share a single `MutationObserver` instance — settle detection = "mutations stopped" and the collected mutations become the state delta for learning.
